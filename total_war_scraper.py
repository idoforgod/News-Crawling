import logging
from bs4 import BeautifulSoup
import trafilatura
from typing import Optional, Dict

logger = logging.getLogger(__name__)

class TotalWarScraper:
    """
    ëª¨ë“  í‘œì¤€ í¬ë¡¤ë§ì´ ì‹¤íŒ¨í–ˆì„ ë•Œ ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ê°€ë™.
    ë¸Œë¼ìš°ì € ì—ë®¬ë ˆì´ì…˜ì„ ì´ë™ì›í•˜ì—¬ 'ë°˜ë“œì‹œ' ì„ë¬´ ì™„ìˆ˜.
    ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ë°˜ë³µ í˜¸ì¶œ ì‹œ ì„±ëŠ¥ ìµœì í™”.
    """
    def __init__(self):
        self.driver = None
        self._consecutive_failures = 0
        self._MAX_FAILURES_BEFORE_RESTART = 3

    def _init_stealth_browser(self):
        import undetected_chromedriver as uc
        options = uc.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')
        return uc.Chrome(options=options)

    def _ensure_browser(self):
        """ë¸Œë¼ìš°ì € lazy init + ì—°ì† ì‹¤íŒ¨ ì‹œ ì¬ìƒì„±"""
        if self.driver and self._consecutive_failures >= self._MAX_FAILURES_BEFORE_RESTART:
            logger.warning("[TOTAL WAR] ì—°ì† ì‹¤íŒ¨ í•œë„ ë„ë‹¬, ë¸Œë¼ìš°ì € ì¬ì‹œì‘")
            self._kill_browser()

        if not self.driver:
            logger.info("[TOTAL WAR] ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”")
            self.driver = self._init_stealth_browser()
            self._consecutive_failures = 0

    def _kill_browser(self):
        """ë‚´ë¶€ ë¸Œë¼ìš°ì € ì •ë¦¬"""
        if self.driver:
            try:
                self.driver.quit()
            except Exception:
                pass
            self.driver = None

    def close(self):
        """ì™¸ë¶€ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•  ë•Œ ì‚¬ìš©"""
        logger.info("[TOTAL WAR] ë¸Œë¼ìš°ì € ëª…ì‹œì  ì¢…ë£Œ")
        self._kill_browser()

    def scrape_with_all_means(self, url: str) -> Optional[Dict]:
        """
        BS4 -> Trafilatura -> Browser Emulation ìˆœìœ¼ë¡œ ëª¨ë“  ë¬´ê¸° ì‚¬ìš©
        ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”.
        """
        logger.warning(f"ğŸš€ [TOTAL WAR] ì§ì ‘ ì ‘ì† ë° ë¸Œë¼ìš°ì € ì—ë®¬ë ˆì´ì…˜ ê°€ë™: {url}")

        try:
            self._ensure_browser()
            self.driver.get(url)

            # WebDriverWait: 5ì´ˆ ë‚´ ì½˜í…ì¸  ê°ì§€ ì‹œ ì¡°ê¸° íƒˆì¶œ
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.webdriver.common.by import By
            try:
                WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.TAG_NAME, "p"))
                )
            except Exception:
                pass  # íƒ€ì„ì•„ì›ƒì´ì–´ë„ ì§„í–‰ (ì¼ë¶€ ì‚¬ì´íŠ¸ëŠ” p íƒœê·¸ ì—†ì´ êµ¬ì„±)

            html = self.driver.page_source
            soup = BeautifulSoup(html, 'lxml')

            # 1. Trafilatura ì¬ì‹œë„ (ë Œë”ë§ëœ HTML ê¸°ë°˜)
            content = trafilatura.extract(html)

            # 2. ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë°€ë„ ê¸°ë°˜ ê°•ì œ ì¶”ì¶œ
            if not content or len(content) < 300:
                p_tags = soup.select("p")
                content = "\n".join([p.get_text(strip=True) for p in p_tags if len(p.get_text(strip=True)) > 20])

            title = ""
            title_candidates = [soup.title.string if soup.title else None, soup.find("h1"), soup.find("h2")]
            for cand in title_candidates:
                if cand:
                    title = cand.get_text(strip=True) if hasattr(cand, 'get_text') else str(cand)
                    break

            if content and len(content) > 200:
                logger.info(f"âœ… [TOTAL WAR] ì„ë¬´ ì™„ìˆ˜: {title[:20]}")
                self._consecutive_failures = 0
                return {"title": title, "content": content}

            self._consecutive_failures += 1
            return None

        except Exception as e:
            logger.error(f"[TOTAL WAR] ìµœí›„ì˜ ìˆ˜ë‹¨ë§ˆì € ì‹¤íŒ¨: {e}")
            self._consecutive_failures += 1
            return None
